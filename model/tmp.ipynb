{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from abc import abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from numbers import Number\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from choices import *\n",
    "from config_base import BaseConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "from nn import (avg_pool_nd, conv_nd, linear, normalization,\n",
    "                 timestep_embedding, torch_checkpoint, zero_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.rand(3, 100, 100)\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 100, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 100, 100, 1]), torch.Size([1, 100, 100, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(n[..., None], 2, dim=0)[0].shape, torch.chunk(n[..., None], 2, dim=0)[1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import *\n",
    "from templates_latent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = ffhq256_autoenc_latent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [attr for attr in dir(conf) if not callable(getattr(conf, attr)) and not attr.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'T_eval',\n",
       " 'T_sampler',\n",
       " 'accum_batches',\n",
       " 'autoenc_mid_attn',\n",
       " 'base_dir',\n",
       " 'batch_size',\n",
       " 'batch_size_effective',\n",
       " 'batch_size_eval',\n",
       " 'beatgans_gen_type',\n",
       " 'beatgans_loss_type',\n",
       " 'beatgans_model_mean_type',\n",
       " 'beatgans_model_var_type',\n",
       " 'beatgans_rescale_timesteps',\n",
       " 'beta_scheduler',\n",
       " 'continue_from',\n",
       " 'data_cache_dir',\n",
       " 'data_name',\n",
       " 'data_path',\n",
       " 'data_val_name',\n",
       " 'diffusion_type',\n",
       " 'dropout',\n",
       " 'ema_decay',\n",
       " 'eval_ema_every_samples',\n",
       " 'eval_every_samples',\n",
       " 'eval_num_images',\n",
       " 'eval_path',\n",
       " 'eval_programs',\n",
       " 'fid_cache',\n",
       " 'fid_use_torch',\n",
       " 'fp16',\n",
       " 'generate_dir',\n",
       " 'grad_clip',\n",
       " 'img_size',\n",
       " 'latent_T_eval',\n",
       " 'latent_beta_scheduler',\n",
       " 'latent_clip_sample',\n",
       " 'latent_gen_type',\n",
       " 'latent_infer_path',\n",
       " 'latent_loss_type',\n",
       " 'latent_model_mean_type',\n",
       " 'latent_model_var_type',\n",
       " 'latent_rescale_timesteps',\n",
       " 'latent_znormalize',\n",
       " 'logdir',\n",
       " 'lr',\n",
       " 'manipulate_cls',\n",
       " 'manipulate_loss',\n",
       " 'manipulate_mode',\n",
       " 'manipulate_seed',\n",
       " 'manipulate_shots',\n",
       " 'manipulate_znormalize',\n",
       " 'model_conf',\n",
       " 'model_name',\n",
       " 'model_out_channels',\n",
       " 'model_type',\n",
       " 'name',\n",
       " 'net_attn',\n",
       " 'net_autoenc_stochastic',\n",
       " 'net_beatgans_attn_head',\n",
       " 'net_beatgans_embed_channels',\n",
       " 'net_beatgans_gradient_checkpoint',\n",
       " 'net_beatgans_resnet_cond_channels',\n",
       " 'net_beatgans_resnet_scale_at',\n",
       " 'net_beatgans_resnet_two_cond',\n",
       " 'net_beatgans_resnet_use_zero_module',\n",
       " 'net_ch',\n",
       " 'net_ch_mult',\n",
       " 'net_enc_attn',\n",
       " 'net_enc_channel_mult',\n",
       " 'net_enc_grad_checkpoint',\n",
       " 'net_enc_k',\n",
       " 'net_enc_num_cls',\n",
       " 'net_enc_num_res_blocks',\n",
       " 'net_enc_pool',\n",
       " 'net_enc_use_time',\n",
       " 'net_latent_activation',\n",
       " 'net_latent_channel_mult',\n",
       " 'net_latent_condition_bias',\n",
       " 'net_latent_dropout',\n",
       " 'net_latent_layers',\n",
       " 'net_latent_net_last_act',\n",
       " 'net_latent_net_type',\n",
       " 'net_latent_num_hid_channels',\n",
       " 'net_latent_num_time_layers',\n",
       " 'net_latent_skip_layers',\n",
       " 'net_latent_time_emb_channels',\n",
       " 'net_latent_time_last_act',\n",
       " 'net_latent_use_norm',\n",
       " 'net_num_input_res_blocks',\n",
       " 'net_num_res_blocks',\n",
       " 'net_resblock_updown',\n",
       " 'num_workers',\n",
       " 'optimizer',\n",
       " 'parallel',\n",
       " 'postfix',\n",
       " 'pretrain',\n",
       " 'sample_every_samples',\n",
       " 'sample_size',\n",
       " 'save_every_samples',\n",
       " 'seed',\n",
       " 'style_ch',\n",
       " 'total_samples',\n",
       " 'train_cond0_prob',\n",
       " 'train_interpolate_img',\n",
       " 'train_interpolate_prob',\n",
       " 'train_mode',\n",
       " 'train_pred_xstart_detach',\n",
       " 'use_cache_dataset',\n",
       " 'warmup',\n",
       " 'weight_decay',\n",
       " 'work_cache_dir']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ViewEncoderConfig(BaseConfig):\n",
    "    image_size: int\n",
    "    in_channels: int\n",
    "    model_channels: int\n",
    "    out_hid_channels: int\n",
    "    out_channels: int\n",
    "    num_res_blocks: int\n",
    "    attention_resolutions: Tuple[int]\n",
    "    dropout: float = 0\n",
    "    channel_mult: Tuple[int] = (1, 2, 4, 8)\n",
    "    use_time_condition: bool = False\n",
    "    conv_resample: bool = True\n",
    "    dims: int = 2\n",
    "    use_checkpoint: bool = False\n",
    "    num_heads: int = 1\n",
    "    num_head_channels: int = -1\n",
    "    resblock_updown: bool = False\n",
    "    use_new_attention_order: bool = False\n",
    "    pool: str = 'adaptivenonzero'\n",
    "\n",
    "    def make_model(self):\n",
    "        return ViewEncoderModel(self)\n",
    "\n",
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, conf: ViewEncoderConfig):\n",
    "        super().__init__(conf)\n",
    "        self.conf = conf\n",
    "\n",
    "        self.camera_mlp = nn.Sequential( # dropout?\n",
    "                linear(conf.model_channels, conf.out_channels),\n",
    "                nn.SiLU(),\n",
    "                linear(conf.out_channels, conf.out_channels),\n",
    "                nn.SiLU(),\n",
    "                linear(conf.out_channels, conf.out_channels),\n",
    "                # nn.SiLU(),\n",
    "                # linear(conf.out_channels, conf.out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, cam, mesh, tex):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ViewEncoderConfig(BaseConfig):\n",
    "    image_size: int\n",
    "    in_channels: int\n",
    "    model_channels: int\n",
    "    out_hid_channels: int\n",
    "    out_channels: int\n",
    "    num_res_blocks: int\n",
    "    attention_resolutions: Tuple[int]\n",
    "    dropout: float = 0\n",
    "    channel_mult: Tuple[int] = (1, 2, 4, 8)\n",
    "    use_time_condition: bool = False\n",
    "    conv_resample: bool = True\n",
    "    dims: int = 2\n",
    "    use_checkpoint: bool = False\n",
    "    num_heads: int = 1\n",
    "    num_head_channels: int = -1\n",
    "    resblock_updown: bool = False\n",
    "    use_new_attention_order: bool = False\n",
    "    pool: str = 'adaptivenonzero'\n",
    "\n",
    "    def make_model(self):\n",
    "        return ViewEncoderModel(self)\n",
    "\n",
    "\n",
    "class ViewEncoderModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The half UNet model with attention and timestep embedding.\n",
    "\n",
    "    For usage, see UNet.\n",
    "    \"\"\"\n",
    "    def __init__(self, conf: ViewEncoderConfig):\n",
    "        super().__init__()\n",
    "        self.conf = conf\n",
    "        self.dtype = th.float32\n",
    "\n",
    "        if conf.use_time_condition:\n",
    "            time_embed_dim = conf.model_channels * 4\n",
    "            self.time_embed = nn.Sequential(\n",
    "                linear(conf.model_channels, time_embed_dim),\n",
    "                nn.SiLU(),\n",
    "                linear(time_embed_dim, time_embed_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_embed_dim = None\n",
    "\n",
    "        self.input_blocks =  nn.ModuleList(TimestepEmbedSequential(*[ # dropout?\n",
    "                linear(conf.model_channels, conf.out_channels),\n",
    "                nn.SiLU(),\n",
    "                linear(conf.out_channels, conf.out_channels),\n",
    "                # nn.SiLU(),\n",
    "                # linear(conf.out_channels, conf.out_channels),\n",
    "                ])\n",
    "            )\n",
    "\n",
    "    def forward(self, x, t=None, return_2d_feature=False):\n",
    "        \"\"\"\n",
    "        Apply the model to an input batch.\n",
    "\n",
    "        :param x: an [N x C x ...] Tensor of inputs.\n",
    "        :param timesteps: a 1-D batch of timesteps.\n",
    "        :return: an [N x K] Tensor of outputs.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        h = x.type(self.dtype)\n",
    "        for module in self.input_blocks:\n",
    "            h = module(h)\n",
    "\n",
    "        h = h.type(x.dtype)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9999999403953552, 0.0, 0.0, 0.0], [0.0, -0.25881901383399963, 0.9659258723258972, 2.897777557373047], [0.0, 0.9659258723258972, 0.258819043636322, 0.7764571309089661], [0.0, 0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../datasets/custom/train/transforms.json\", \"r\") as json_file:\n",
    "    tmp = json.load(json_file)\n",
    "mat = tmp['frames'][0]['transform_matrix']\n",
    "print(mat)\n",
    "mat = torch.DoubleTensor(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000, -0.2588,  0.9659],\n",
       "         [ 0.0000,  0.9659,  0.2588]], dtype=torch.float64),\n",
       " tensor([0.0000, 2.8978, 0.7765], dtype=torch.float64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[:3,:3], mat[:3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), torch.Size([3]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[:3,:3].flatten().shape, mat[:3,3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((mat[:3,:3].flatten(),mat[:3,3])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 128, 128) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jiyouseo/diffae/model/tmp.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jiyouseo/diffae/model/tmp.ipynb#ch0000028?line=7'>8</a>\u001b[0m m_o \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(npy_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/m_o/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm_o_\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m)[img_index]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jiyouseo/diffae/model/tmp.ipynb#ch0000028?line=8'>9</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m20\u001b[39m,\u001b[39m2\u001b[39m,i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jiyouseo/diffae/model/tmp.ipynb#ch0000028?line=9'>10</a>\u001b[0m ax\u001b[39m.\u001b[39;49mimshow(x_s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jiyouseo/diffae/model/tmp.ipynb#ch0000028?line=10'>11</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m20\u001b[39m,\u001b[39m2\u001b[39m,i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jiyouseo/diffae/model/tmp.ipynb#ch0000028?line=11'>12</a>\u001b[0m ax\u001b[39m.\u001b[39mimshow(m_o)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=449'>450</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=450'>451</a>\u001b[0m     warn_deprecated(\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=451'>452</a>\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=452'>453</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=453'>454</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=454'>455</a>\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/_api/deprecation.py?line=455'>456</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1408'>1409</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1409'>1410</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1410'>1411</a>\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1411'>1412</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1413'>1414</a>\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1414'>1415</a>\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/__init__.py?line=1415'>1416</a>\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5488\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5480'>5481</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5481'>5482</a>\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap, norm, interpolation,\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5482'>5483</a>\u001b[0m                       origin, extent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5483'>5484</a>\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5484'>5485</a>\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5485'>5486</a>\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5487'>5488</a>\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5488'>5489</a>\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5489'>5490</a>\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=5490'>5491</a>\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=710'>711</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=712'>713</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=713'>714</a>\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=714'>715</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=715'>716</a>\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=717'>718</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=718'>719</a>\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=719'>720</a>\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=720'>721</a>\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=721'>722</a>\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jiyouseo/anaconda3/envs/diffae/lib/python3.8/site-packages/matplotlib/image.py?line=722'>723</a>\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 128, 128) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x2880 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,40))\n",
    "ax = [0]* 40\n",
    "i = 1\n",
    "img_index = 0\n",
    "npy_path = '/home/jiyouseo/diffae/checkpoints/viewsyn_autoenc/npy_folder'\n",
    "while True:\n",
    "    x_s = np.load(npy_path + '/x_s/' + f'x_s_{j}.npy')[img_index]\n",
    "    m_o = np.load(npy_path + '/m_o/' + f'm_o_{j}.npy')[img_index]\n",
    "    ax = fig.add_subplot(20,2,i)\n",
    "    ax.imshow(x_s)\n",
    "    ax = fig.add_subplot(20,2,i+1)\n",
    "    ax.imshow(m_o)\n",
    "    i += 2\n",
    "    if i == 40:\n",
    "        break\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90ceafba792b69c8ed11b835c495be6b5f696b5660975e55561f66b55c7d3cad"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('diffae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
